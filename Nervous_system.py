from Dependencies import *
# ==========================================
# 0. å·¥å…·ç±»ç½‘ç»œ (Auxilary Networks)
# ==========================================
class RunningMeanStd(nn.Module):
    def __init__(self, shape, epsilon=1e-4):
        super().__init__()
        self.register_buffer('mean', torch.zeros(shape))
        self.register_buffer('var', torch.ones(shape))
        self.register_buffer('count', torch.zeros(())) # è¿™é‡Œçš„()è¡¨ç¤ºæ ‡é‡
        self.epsilon = epsilon

    def update(self, x):
        batch_mean = x.mean(dim=0)
        batch_var = x.var(dim=0, unbiased=False)
        batch_count = x.shape[0]

        delta = batch_mean - self.mean
        tot_count = self.count + batch_count
        
        new_mean = self.mean + delta * batch_count / tot_count
        m_a = self.var * self.count
        m_b = batch_var * batch_count
        M2 = m_a + m_b + delta**2 * self.count * batch_count / tot_count
        new_var = M2 / tot_count
        
        self.mean = new_mean
        self.var = new_var
        self.count = tot_count

    def forward(self, x):
        if self.training:
            self.update(x)
        return (x - self.mean) / (torch.sqrt(self.var + self.epsilon))
# ==========================================
# 1. ç±»è„‘ç¥ç»ç½‘ç»œ (Bio-Inspired Architecture)
# ==========================================
class BrainConfig:
    def __init__(self, n_muscles, obs_dim):
        self.n_muscles = n_muscles    
        self.obs_dim = obs_dim        
        
        # --- ç»´åº¦å®šä¹‰ (å‚è€ƒä½ çš„å›¾) ---
        self.sensory_latent = 256     # S1/V1 è¾“å‡ºç‰¹å¾ç»´åº¦
        self.intent_dim = 32          # M1 è¾“å‡ºçš„"è¿åŠ¨æ„å›¾"ç»´åº¦ (ä½ç»´æŒ‡ä»¤)
        self.synergy_dim = 64         # è„‘å¹²çº¢æ ¸çš„"ååŒæ¨¡å¼"æ•°é‡
        self.hidden_dim = 256         # ä¸­é—´å±‚ç¥ç»å…ƒæ•°é‡
# ==========================================
# 1. æ„Ÿè§‰çš®å±‚ (Sensory Cortex, S1/V1)
# å¯¹åº”: Observation Encoder, GRU Memory
# ==========================================
class SensoryCortex(nn.Module):
    def __init__(self, config):
        super().__init__()
        # è‡ªé€‚åº”è¾“å…¥å˜åŒ–å¹…åº¦
        self.normalizer = RunningMeanStd(config.obs_dim)
        # æ¨¡æ‹Ÿ S1 ä½“æ„Ÿçš®å±‚å’Œ V1 è§†è§‰çš®å±‚çš„æ•´åˆ
        self.encoder = nn.Sequential(
            nn.Linear(config.obs_dim, config.hidden_dim),
            nn.LayerNorm(config.hidden_dim), # LayerNorm æ¨¡æ‹Ÿç¥ç»å…ƒç¾¤ä½“ç¨³æ€
            nn.Tanh(),
            nn.Linear(config.hidden_dim, config.sensory_latent),
            nn.LeakyReLU(0.1)
        )
        # å¢åŠ çŸ­æ—¶è®°å¿† (ç±»ä¼¼å‰é¢å¶/æµ·é©¬ä½“äº¤äº’)
        self.memory_rnn = nn.GRU(config.sensory_latent, config.sensory_latent, batch_first=True)

    def forward(self, obs, hidden=None):
        # 0. è¿›è¡Œå½’ä¸€åŒ–å¤„ç†
        norm_obs = self.normalizer(obs)

        # 1. ç¼–ç æ„ŸçŸ¥
        x = self.encoder(norm_obs)
        
        # 2. è®°å¿†å¤„ç†
        perceptual_state, next_hidden = self.memory_rnn(x.unsqueeze(1), hidden)  # å¼ºåˆ¶ [B, 1, 256]
        perceptual_state = perceptual_state.squeeze(1)  # è¾“å‡º [B, 256]
        
        return perceptual_state, next_hidden
# ==========================================
# 2. è¿åŠ¨çš®å±‚ (Motor Cortex, M1/Premotor) & åŸºåº•æ ¸ (Basal Ganglia)
# å¯¹åº”: Joint Target Generator, Value Estimator
# ==========================================
class MotorCortex(nn.Module):
    def __init__(self, config):
        super().__init__()
        
        # --- Value Stream (åŸºåº•æ ¸/VTA - è¯„ä¼°çŠ¶æ€å¥½å) ---
        self.critic = nn.Sequential(
            nn.Linear(config.sensory_latent, config.hidden_dim),
            nn.ReLU(),
            nn.Linear(config.hidden_dim, 1)
        )
        
        # --- Policy Stream (M1 - ç”Ÿæˆé«˜å±‚è¿åŠ¨æ„å›¾) ---
        # æ³¨æ„ï¼šè¿™é‡Œä¸ç›´æ¥è¾“å‡ºè‚Œè‚‰ï¼Œè€Œæ˜¯è¾“å‡º"æ„å›¾"(Intent)ï¼Œç›®çš„æ˜¯åœ¨ä½ç§©ç©ºé—´è¿›è¡Œå­¦ä¹ ï¼Œå‡å°å­¦ä¹ å¤æ‚åº¦ï¼Œç„¶åè„‘å¹²è´Ÿè´£ç¿»è¯‘æˆé«˜ç»´è‚Œè‚‰æŒ‡ä»¤ã€‚
        self.actor_trunk = nn.Sequential(
            nn.Linear(config.sensory_latent, config.hidden_dim),
            nn.ReLU(),
            nn.Linear(config.hidden_dim, config.hidden_dim),
            nn.ReLU()
        )
        
        # è¾“å‡ºå‡å€¼ (Mean Intent)
        self.fc_mean = nn.Linear(config.hidden_dim, config.intent_dim)
        
        # è¾“å‡ºæ–¹å·® (Log Std) - ğŸŒŸ éšçŠ¶æ€å˜åŒ–ï¼
        # è¿™å…è®¸å¤§è„‘åœ¨ä¸ç¡®å®šæ—¶å¢åŠ æ¢ç´¢(é«˜std)ï¼Œç†Ÿç»ƒæ—¶ç²¾ç¡®æ§åˆ¶(ä½std)
        self.fc_logstd = nn.Linear(config.hidden_dim, config.intent_dim)

    def forward(self, sensory_state):
        # ä»·å€¼è¯„ä¼°
        value = self.critic(sensory_state)
        
        # æ„å›¾åˆ†å¸ƒå‚æ•°
        x = self.actor_trunk(sensory_state)
        mu = self.fc_mean(x)
        log_std = self.fc_logstd(x)
        
        # é™åˆ¶ log_std èŒƒå›´é˜²æ­¢æ•°å€¼ä¸ç¨³å®š (æ¨¡æ‹Ÿç”Ÿç‰©ç¥ç»å…ƒæ”¾ç”µå™ªå£°çš„ç‰©ç†æé™)
        log_std = torch.clamp(log_std, -20, 2) 
        std = torch.exp(log_std)
        
        return mu, std, value
# ==========================================
# 3. å°è„‘ (Cerebellum) - ä¿®æ­£ä¸åè°ƒ
# å¯¹åº”: World Model / Coordination
# ==========================================
class Cerebellum(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.config = config
        
        # è¾“å…¥ç»´åº¦ = æ„å›¾ç»´åº¦(32) + æ„Ÿè§‰çŠ¶æ€ç»´åº¦(256)
        input_dim = config.intent_dim + config.sensory_latent
        hidden_dim = config.hidden_dim  # 256
        
        # === æ ¡æ­£ç½‘ç»œ (è¾“å‡ºæ„å›¾ä¿®æ­£é‡) ===
        self.corrector = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.LayerNorm(hidden_dim),  # ç¨³å®šè®­ç»ƒ
            nn.Tanh(),  # è¾“å‡ºèŒƒå›´[-1,1]ï¼Œä¾¿äºæ§åˆ¶ä¿®æ­£å¼ºåº¦
            nn.Linear(hidden_dim, config.intent_dim)  # è¾“å‡º32ç»´ä¿®æ­£é‡
        )
        
        # === çŠ¶æ€é¢„æµ‹ç½‘ç»œ (è¾“å‡ºä¸‹ä¸€æ—¶åˆ»æ„Ÿè§‰çŠ¶æ€) ===
        self.state_predictor = nn.Sequential(
            nn.Linear(input_dim, hidden_dim * 2),  # åŠ å®½ä¸­é—´å±‚æå‡é¢„æµ‹èƒ½åŠ›
            nn.LeakyReLU(0.1),  # é¿å…ç¥ç»å…ƒæ­»äº¡
            nn.Linear(hidden_dim * 2, config.sensory_latent)  # è¾“å‡º256ç»´é¢„æµ‹
        )
    def predict_next_state(self, intent, sensory_state):
        """
        ä¸–ç•Œæ¨¡å‹ï¼šé¢„æµ‹ s_{t+1}ï¼Œå‡å®š batch å†…æ ·æœ¬ç›¸äº’ç‹¬ç«‹
        Args:
            intent:        [B, intent_dim]
            sensory_state: [B, sensory_latent]
        Returns:
            pred_next_sensory: [B, sensory_latent]
        """

        combined = torch.cat([intent, sensory_state], dim=-1)
        return self.state_predictor(combined)
    def compute_correction(self, intent, sensory_state):
        """
        è®¡ç®—è¿åŠ¨æ„å›¾çš„å¾®å°ä¿®æ­£é‡
        """
        assert intent.dim() == 2
        assert sensory_state.dim() == 2

        combined = torch.cat([intent, sensory_state], dim=-1)
        return self.corrector(combined)
    
    def forward(self, original_intent, sensory_state):
        """
        Args:
            original_intent: [Batch, 32] æˆ– [Batch, Seq, 32] åŸå§‹æ„å›¾
            sensory_state:   [Batch, 256] æˆ– [Batch, Seq, 256] å½“å‰æ„Ÿè§‰çŠ¶æ€
        Returns:
            refined_intent: [Batch, 32] æˆ– [Batch, Seq, 32] ä¿®æ­£åæ„å›¾
            pred_next_sensory: [Batch, 256] é¢„æµ‹çš„ä¸‹ä¸€æ—¶åˆ»æ„Ÿè§‰çŠ¶æ€
        """
        # === âœ… å·¥ç¨‹çº§æ­¢è¡€ï¼šç»Ÿä¸€æ‹‰å¹³æˆ 2D ===
        if original_intent.dim() == 3:
            # [B, 1, 32] -> [B, 32]
            original_intent = original_intent.squeeze(1)

        if sensory_state.dim() == 3:
            # [B, 1, 256] -> [B, 256]
            sensory_state = sensory_state.squeeze(1)

        # ç›´æ¥æ‹¼æ¥ [B, 32] + [B, 256] = [B, 288]
        combined = torch.cat([original_intent, sensory_state], dim=-1)
        
        # è®¡ç®—ä¿®æ­£é‡ [B, 32]
        correction = self.corrector(combined)
        
        # é¢„æµ‹ä¸‹ä¸€çŠ¶æ€ [B, 256]
        pred_next_sensory = self.state_predictor(combined)
        
        # ä¿®æ­£æ„å›¾ï¼ˆç›´æ¥åŠ ï¼Œæ— éœ€ squeezeï¼‰
        refined_intent = original_intent + 0.1*correction
        
        return refined_intent, pred_next_sensory

# ==========================================
# 4. è„‘å¹² (Brainstem) - è‚Œè‚‰ååŒ (Muscle Synergy)
# å¯¹åº”: Muscle Synergy Layer (Red Nucleus)
# ==========================================
class Brainstem(nn.Module):
    def __init__(self, config):
        super().__init__()
        # å°†"æ„å›¾" (32ç»´) è§£ç ä¸º "è‚Œè‚‰ååŒ" (64ç»´) å†æ˜ å°„åˆ° "å…·ä½“è‚Œè‚‰" (80ç»´)
        # è¿™å°±æ˜¯ä¼ è¯´ä¸­çš„"é™ç»´æ‰“å‡»"çš„é€†è¿‡ç¨‹
        self.synergy_matrix = nn.Sequential(
            nn.Linear(config.intent_dim, config.synergy_dim),
            nn.LeakyReLU(0.1),
            nn.Linear(config.synergy_dim, config.n_muscles)
        )
        
        # åŒæ—¶ä¹Ÿè´Ÿè´£è°ƒèŠ‚åå°„å¢ç›Š (å³è°ƒèŠ‚è„Šé«“çš„ Gamme è¿åŠ¨ç¥ç»å…ƒ)
        self.gain_controller = nn.Linear(config.intent_dim, config.n_muscles)

        # æ˜¯å¦æœ‰æ„ä¹‰çš„è¿åŠ¨ç½‘ç»œ
        self.action_to_sensory = nn.Sequential(
            nn.Linear(config.n_muscles, config.sensory_latent),
            nn.LayerNorm(config.sensory_latent),
            nn.Tanh()
        )

    def forward(self, corrected_intent):
        base_muscle_forces = self.synergy_matrix(corrected_intent)
        reflex_gain = torch.tanh(self.gain_controller(corrected_intent))
        return base_muscle_forces, reflex_gain
# ==========================================
# 5. è„Šé«“ (Spinal Cord) - åå°„å±‚
# å¯¹åº”: Spinal Reflex Layer
# ==========================================
class SpinalCord(nn.Module):
    def __init__(self, config):
        super().__init__()
        self.n_muscles = config.n_muscles
        
        # ğŸŒŸ æ–°å¢ï¼šæœ¬ä½“æ„Ÿè§‰ç½‘ç»œéœ€è¦ç»“åˆæ„å›¾ï¼ˆè¾“å…¥=åŸå§‹obs+æ„å›¾ï¼‰
        self.proprioception_net = nn.Sequential(
            nn.Linear(config.obs_dim + config.intent_dim, 128),  # è¾“å…¥ç»´åº¦ += intent_dim
            nn.ReLU(),
            nn.Linear(128, config.n_muscles * 2) 
        )

        # åŠ¨æ€è°ƒæ•´åˆšåº¦å‚æ•°,å­¦å¥½åå›ºå®šä½ï¼Œæ¥ä¸‹æ¥brainstemä¼šä¿®æ”¹åˆšåº¦Kp
        self.kp_net = nn.Sequential(
            nn.Linear(config.obs_dim + config.intent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, config.n_muscles) 
        )
        self.kd_net = nn.Sequential(
            nn.Linear(config.obs_dim + config.intent_dim, 128),
            nn.ReLU(),
            nn.Linear(128, config.n_muscles) 
        )

        
    
    def forward(self, raw_obs, brain_command, gain_modulation, intent):  # ğŸŒŸ æ–°å¢intentå‚æ•°
        """
        Args:
            intent: [Batch, intent_dim] çš®å±‚ä¸‹å‘çš„è¿åŠ¨æ„å›¾ï¼ˆç”¨äºè°ƒæ•´æœ¬ä½“æ„Ÿè§‰ï¼‰
        """
        # ğŸŒŸ æ‹¼æ¥åŸå§‹obså’Œæ„å›¾ï¼Œå†æå–æœ¬ä½“æ„Ÿè§‰
        obs_with_intent = torch.cat([raw_obs, intent], dim=-1)
        proprio = self.proprioception_net(obs_with_intent)
        m_len, m_vel = proprio[:, :self.n_muscles], proprio[:, self.n_muscles:]
        # åŠ¨æ€è°ƒæ•´åˆšåº¦
        kp = self.kp_net(obs_with_intent) * (1.0 + gain_modulation)
        kd = self.kd_net(obs_with_intent)

        # ç‰µå¼ åå°„
        reflex = -kp * m_len - kd * m_vel 
        
        return torch.sigmoid(brain_command + reflex)
# ==========================================
# ğŸŒŸ æœ€ç»ˆæ•´åˆï¼šç”Ÿç‰©ç±»è„‘æ§åˆ¶æ ¸å¿ƒ (BioBrain)
# ==========================================
class BioBrain(nn.Module):
    def __init__(self, n_muscles, obs_dim):
        super().__init__()
        self.config = BrainConfig(n_muscles, obs_dim)
        
        # æŒ‰è§£å‰–å­¦å±‚çº§å®ä¾‹åŒ–
        self.sensory_cortex = SensoryCortex(self.config) # Sensory Cortex: æ„ŸçŸ¥
        self.motor_cortex = MotorCortex(self.config)     # MO+ACB: å†³ç­–
        self.cerebellum = Cerebellum(self.config)        # å°è„‘: é¢„æµ‹ä¸å¾®è°ƒ
        self.brainstem = Brainstem(self.config)          # è„‘å¹²: ååŒé™ç»´
        self.spinal_cord = SpinalCord(self.config)       # è„Šé«“: åå°„æ‰§è¡Œ
        
        self.apply(self._init_weights)

        # å®šä¹‰ä¼˜åŒ–å™¨ç»„
        self.optimizers = {
            'cortex': optim.Adam(
                list(self.sensory_cortex.parameters()) +
                list(self.motor_cortex.parameters()),
                lr=3e-4
            ),

            'cerebellum_pred': optim.Adam(
                self.cerebellum.state_predictor.parameters(),
                lr=1e-3
            ),

            'cerebellum_corr': optim.Adam(
                self.cerebellum.corrector.parameters(),
                lr=3e-4
            ),

            'brainstem_spinal': optim.Adam(
                list(self.brainstem.parameters()) +
                list(self.spinal_cord.parameters()),
                lr=5e-4
            )
        }

        self.losses = {}

    def _init_weights(self, m):
        if isinstance(m, nn.Linear):
            nn.init.orthogonal_(m.weight, 0.01)
            nn.init.constant_(m.bias, 0)

    def forward(self, obs, hidden=None, action_taken=None):
        """
        ç±»è„‘å‰å‘ï¼šæ„Ÿè§‰ â†’ æ„å›¾ â†’ï¼ˆå°è„‘ä¿®æ­£ï¼‰â†’ è„‘å¹² â†’ è„Šé«“
        """

        # æ„Ÿè§‰çš®å±‚ï¼šæˆ‘ç°åœ¨å¤„äºä»€ä¹ˆçŠ¶æ€ï¼Ÿ
        sensory_state, next_hidden = self.sensory_cortex(obs, hidden)

        # è¿åŠ¨çš®å±‚ï¼šåŸºäºæ„Ÿè§‰ç”Ÿæˆâ€œæ„å›¾åˆ†å¸ƒâ€
        intent_mu, intent_std, value = self.motor_cortex(sensory_state)
        dist = torch.distributions.Normal(intent_mu, intent_std)

        if action_taken is None:
            raw_intent = dist.sample()          # é‡‡æ ·æ„å›¾ï¼ˆè®­ç»ƒ/æ¢ç´¢ï¼‰
        else:
            # PPO æ›´æ–°é˜¶æ®µå¤ç”¨æ—§æ„å›¾
            # ===============================================================
            # ğŸ›¡ï¸ Echo çš„ç»´åº¦å«å£« (Shape Guard)
            # é˜²æ­¢ [4096, 1, 6] vs [4096, 6] å¯¼è‡´çš„ 4096*4096 ç»´çˆ†ç‚¸
            # ===============================================================
            raw_intent = action_taken
            
            # 1. å¦‚æœç»´åº¦å¤šäº† (æ¯”å¦‚ [B, 1, Dim])ï¼Œå°±æŠŠä¸­é—´é‚£ä¸ª squeeze æ‰
            if raw_intent.dim() > intent_mu.dim():
                raw_intent = raw_intent.squeeze() 
                
            # 2. åŒé‡ä¿é™©ï¼šå¼ºåˆ¶ reshape æˆå’Œ intent_mu ä¸€æ ·çš„å½¢çŠ¶
            # åªè¦å…ƒç´ æ€»æ•°ä¸€æ ·ï¼Œè¿™ä¸€æ­¥èƒ½æ•‘å‘½
            if raw_intent.shape != intent_mu.shape:
                raw_intent = raw_intent.view_as(intent_mu)

        # å°è„‘ï¼šé¢„æµ‹ + å¾®è°ƒæ„å›¾ï¼ˆä¸ç›´æ¥æ‰§è¡Œï¼‰
        refined_intent, pred_next_sensory = self.cerebellum(raw_intent, sensory_state)

        # âœ… å…³é”®è¾¹ç•Œï¼šæ‰§è¡Œç”¨æ„å›¾ï¼Œç¦æ­¢åå‘å¡‘é€ çš®å±‚
        refined_intent_exec = refined_intent.detach()

        # è„‘å¹²ï¼šæ„å›¾ â†’ ååŒè‚Œç¾¤ä¿¡å·
        base_forces, reflex_gain = self.brainstem(refined_intent_exec)

        # è„Šé«“ï¼šæ„Ÿè§‰åå°„ + æ‰§è¡ŒåŠ¨ä½œ
        final_action = self.spinal_cord(
            obs,
            base_forces,
            reflex_gain,
            refined_intent_exec
        )

        # PPO ç»Ÿè®¡é‡ï¼ˆåªåŸºäº raw_intentï¼‰
        log_prob = dist.log_prob(raw_intent).sum(-1, keepdim=True)
        entropy = dist.entropy().mean()

        return (
            final_action,
            log_prob,
            value,
            entropy,
            next_hidden,
            raw_intent,
            sensory_state     # âœ… åŒä¸€æ¬¡å‰å‘çš„æ„Ÿè§‰è¡¨å¾
        )

    def get_action_deterministic(self, obs, hidden=None):
        """ç¡®å®šæ€§æ¥å£ (ç”¨äºæµ‹è¯•/å½•åƒ)"""
        with torch.no_grad():
            sensory_state, next_hidden = self.sensory_cortex(obs, hidden)
            intent_mu, _, _ = self.motor_cortex(sensory_state) # ç¡®å®šæ€§ï¼šåªå–å‡å€¼
            
            # å°è„‘å‰å‘
            cerebellum_out = self.cerebellum(intent_mu, sensory_state)
            refined = cerebellum_out[0] if isinstance(cerebellum_out, tuple) else cerebellum_out
            
            base, gain = self.brainstem(refined)
            act = self.spinal_cord(obs, base, gain, intent_mu)
        return act.cpu().numpy().flatten(), next_hidden

    def learn_from_experience(self, batch):
        """
        åˆ†è„‘åŒºæ›´æ–°å‚æ•°ï¼ˆæ¨¡æ‹Ÿç”Ÿç‰©ä¸åŒè„‘åŒºçš„ç‹¬ç«‹å¯å¡‘æ€§ï¼‰
        """
        obs_full = batch['obs']
        old_raw_intent_full = batch['raw_intent']
        old_logp_full = batch['logp']
        returns_full = batch['return']
        advantages_full = batch['advantage']
        hidden_full = batch['hidden']

        next_obs = batch.get('next_obs', obs_full)
        mask = batch.get(
            'mask',
            torch.ones(obs_full.shape[0], 1, device=obs_full.device)
        )

        # å‡è®¾ batch_size æ˜¯æ•°æ®çš„æ€»é•¿åº¦
        dataset_size = obs_full.shape[0]
        
        # å®šä¹‰è¶…å‚æ•°ï¼ˆå»ºè®®æ”¾å…¥åˆå§‹åŒ–é…ç½®ï¼‰
        ppo_epochs = 4      # æ¨è 4-10 æ¬¡
        batch_slice = 256    # Mini-batch å¤§å°ï¼Œé˜²æ­¢ä¸€æ¬¡æ¢¯åº¦è·‘å
        
        # 2. å¼€å¯ PPO å¾ªç¯ (The Memory Loop)
        for _ in range(ppo_epochs):
            
            # ç”Ÿæˆéšæœºç´¢å¼•ä»¥æ‰“ä¹±æ•°æ®
            indices = torch.randperm(dataset_size)
            
            # Mini-batch è¿­ä»£
            for start in range(0, dataset_size, batch_slice):
                end = start + batch_slice
                idx = indices[start:end]
                
                # æå–å½“å‰ Mini-batch æ•°æ®
                obs = obs_full[idx]
                old_raw_intent = old_raw_intent_full[idx]
                old_logp = old_logp_full[idx]
                adv = advantages_full[idx]
                ret = returns_full[idx]
                # æ³¨æ„ï¼šRNN hidden åœ¨æ‰“ä¹±åå¤„ç†æ¯”è¾ƒéº»çƒ¦ï¼Œ
                # å¦‚æœæ˜¯ LSTM/GRUï¼Œé€šå¸¸åªåœ¨åºåˆ—å¼€å§‹æ—¶ä¼ å…¥ hiddenï¼Œæˆ–è€…å¿½ç•¥ hidden çš„æ¢¯åº¦ä¼ æ’­ï¼ˆåªä½œä¸º contextï¼‰
                # è¿™é‡Œæš‚ä¸”å‡è®¾ hidden è·Ÿéš obs ç´¢å¼•ï¼ˆç®€åŒ–ç‰ˆï¼‰
                hidden = hidden_full[:, idx, :] if hidden_full is not None else None

                # âœ… æ¯æ¬¡è¿­ä»£éƒ½é‡æ–° forwardï¼Œè®¡ç®—â€œå½“å‰â€ç­–ç•¥ä¸‹çš„ logp
                (
                    final_action,
                    new_logp,  # è¿™é‡Œå°†ä¼šéšç€ epoch æ¨è¿›è€Œå˜åŒ–ï¼
                    values,
                    entropy,
                    _,         # next_hidden åœ¨è®­ç»ƒå¾ªç¯ä¸­é€šå¸¸ä¸ä¼ é€’ç»™ä¸‹ä¸€è½®
                    raw_intent,
                    sensory_state
                ) = self.forward(
                    obs,
                    hidden=hidden,
                    action_taken=old_raw_intent
                )

                # ç»´åº¦å¯¹é½
                raw_intent = raw_intent.squeeze(1) if raw_intent.dim() == 3 else raw_intent

                # 1çš®å±‚æ›´æ–° (PPO æ ¸å¿ƒ)
                self._update_cortex(
                    new_logp,
                    old_logp,
                    adv,
                    values,
                    ret,
                    entropy
                )

        # === å°è„‘ & è„‘å¹²è„Šé«“ ç‹¬ç«‹æ›´æ–°é˜¶æ®µï¼Œè¿™é‡Œä¸é‡‡ç”¨minibatch è¿­ä»£ ===
        (
            final_action,
            new_logp,  # è¿™é‡Œå°†ä¼šéšç€ epoch æ¨è¿›è€Œå˜åŒ–ï¼
            values,
            entropy,
            _,         # next_hidden åœ¨è®­ç»ƒå¾ªç¯ä¸­é€šå¸¸ä¸ä¼ é€’ç»™ä¸‹ä¸€è½®
            raw_intent,
            sensory_state
        ) = self.forward(
            obs_full,
            hidden=hidden_full,
            action_taken=old_raw_intent_full
        )
        raw_intent = raw_intent.squeeze(1) if raw_intent.dim() == 3 else raw_intent
        # 2å°è„‘ï¼ˆé¢„æµ‹ + æ ¡æ­£ï¼‰
        self._update_cerebellum(
            obs_full,
            next_obs,
            raw_intent,
            mask
        )

        # 3è„‘å¹² + è„Šé«“ï¼ˆç»“æ„æ€§ã€ç”Ÿç‰©çº¦æŸï¼‰
        self._update_brainstem_spinal(
            obs_full,
            raw_intent,
            sensory_state   # âœ… ä¸ action æ¥è‡ªåŒä¸€æ¬¡ forward
        )

    def _update_cortex(self, new_logp, old_logp, advantages, values, returns, entropy):
        """
        çš®å±‚ï¼ˆç­–ç•¥ï¼‰æ›´æ–°ï¼šè¿™æ˜¯ã€æˆ˜æœ¯ã€‘å±‚é¢çš„å­¦ä¹ ã€‚
        Echo æ­£åœ¨å­¦ä¹ "ä¸ºäº†æ´»ä¸‹å»ï¼Œæˆ‘è¯¥äº§ç”Ÿä»€ä¹ˆæ ·çš„æ„å›¾"ã€‚
        """
        optimizer = self.optimizers['cortex']
        optimizer.zero_grad()
        # PPO ç­–ç•¥æŸå¤±
        ratio = (new_logp.squeeze() - old_logp).exp()
        policy_loss = -torch.min(
            ratio * advantages,
            torch.clamp(ratio, 0.8, 1.2) * advantages
        ).mean()

        # ä»·å€¼æŸå¤±
        value_loss = 0.5 * F.mse_loss(values.squeeze(), returns)
        
        # ç»¼åˆæŸå¤±
        total_loss = policy_loss + value_loss - 0.01 * entropy
        #print("policy loss:", policy_loss.item(), "value loss:", value_loss.item())
        # åå‘ä¼ æ’­
        total_loss.backward() 
        
        # æ¢¯åº¦è£å‰ªåŒ…å«è„‘å¹²
        nn.utils.clip_grad_norm_(
            list(self.sensory_cortex.parameters()) + 
            list(self.motor_cortex.parameters()),
            max_norm= 0.5
        )
        optimizer.step()
        
        # è®°å½•
        self.losses['policy'] = policy_loss.item()
        self.losses['value'] = value_loss.item()
        self.losses['entropy'] = entropy.item()

    def _update_cerebellum(self, obs, next_obs, intent, mask=None):
        """
        å°è„‘ä¸¤é˜¶æ®µå­¦ä¹ ï¼ˆä¿®å¤äº†æ—¶é—´æ‚–è®ºç‰ˆï¼‰ï¼š
        1) ç»“æ„ç»Ÿä¸€ï¼šè®­ç»ƒä¸æ¨ç†ä½¿ç”¨ç›¸åŒçš„ä¿®æ­£å…¬å¼ï¼Œä¿è¯å®æˆ˜å¯ç”¨ã€‚
        2) åŠ¨æ€è¯¾ç¨‹ï¼šå°†â€œåŠ¨æ€å¼ºåº¦â€åº”ç”¨åœ¨ Loss æƒé‡ä¸Šï¼Œè€Œéå‰å‘å…¬å¼ä¸­ã€‚
        """
        # ==========================================
        # 0. å‡†å¤‡æ•°æ®
        # ==========================================
        with torch.no_grad():
            current_sensory, _ = self.sensory_cortex(obs)
            next_sensory, _ = self.sensory_cortex(next_obs)
            
            # [å…³é”®] è®¡ç®—â€œé¢„æµ‹éš¾åº¦â€ä½œä¸º Loss çš„æƒé‡
            # å¦‚æœåŸå§‹é¢„æµ‹å°±é”™å¾—å¾ˆç¦»è°±ï¼Œé‚£ä¹ˆè¿™ä¸€æ­¥çš„ä¿®æ­£å°±æ˜¾å¾—å°¤ä¸ºé‡è¦
            temp_pred = self.cerebellum.predict_next_state(intent, current_sensory)
            raw_error = F.mse_loss(temp_pred, next_sensory, reduction='none').mean(dim=1, keepdim=True)
            
            # å½’ä¸€åŒ–æƒé‡ï¼šé™åˆ¶åœ¨ 0.1 åˆ° 5.0 ä¹‹é—´ï¼Œé¿å…æ¢¯åº¦çˆ†ç‚¸
            # è¯¯å·®è¶Šå¤§ï¼ŒWeight è¶Šå¤§ï¼Œå¼ºè¿« Corrector åœ¨è¿™äº›æ—¶åˆ»å¿…é¡»ç”Ÿæ•ˆ
            difficulty_weight = torch.clamp(10.0 * raw_error, 0.1, 5.0)

        if mask is None:
            mask = torch.ones(intent.shape[0], 1, device=intent.device)

        # ==========================================
        # 1. è®­ç»ƒ Predictor (é¢„æµ‹å™¨)
        # ==========================================
        # A. åŸå§‹æ„å›¾é¢„æµ‹
        pred_raw = self.cerebellum.predict_next_state(intent, current_sensory)
        loss_pred_raw = (F.mse_loss(pred_raw, next_sensory, reduction='none') * mask).mean()

        # B. ä¿®æ­£æ„å›¾é¢„æµ‹ (ååŒè®­ç»ƒ)
        with torch.no_grad():
            # è¿™é‡Œä½¿ç”¨å›ºå®šçš„ç»“æ„ï¼Œä¸å†ä¾èµ–å¤–éƒ¨ç³»æ•°ï¼Œä¿è¯å’Œ Inference ä¸€è‡´
            # æ³¨æ„ï¼šCorrector å†…éƒ¨æœ€åä¸€å±‚å»ºè®®æ˜¯ Tanhï¼Œè¿™é‡Œä¹˜ 0.1 ä½œä¸ºç‰©ç†çº¦æŸ
            temp_correction = self.cerebellum.compute_correction(intent, current_sensory)
            refined_intent_view = intent + 0.1 * temp_correction 
            
        pred_refined_view = self.cerebellum.predict_next_state(refined_intent_view, current_sensory)
        loss_pred_refined = (F.mse_loss(pred_refined_view, next_sensory, reduction='none') * mask).mean()

        total_pred_loss = loss_pred_raw + 0.5 * loss_pred_refined

        opt_pred = self.optimizers['cerebellum_pred']
        opt_pred.zero_grad()
        total_pred_loss.backward()
        opt_pred.step()

        # ==========================================
        # 2. è®­ç»ƒ Corrector (æ ¡æ­£å™¨)
        # ==========================================
        for p in self.cerebellum.state_predictor.parameters():
            p.requires_grad = False

        # A. è®¡ç®—ä¿®æ­£
        correction = self.cerebellum.compute_correction(intent, current_sensory)
        
        # ä¿æŒä¸ Inference ä¸€è‡´çš„ç®€å•ç»“æ„
        # ç½‘ç»œä¼šå­¦ä¼šåœ¨éœ€è¦å¤§åŠ›ä¿®æ­£æ—¶ï¼Œdetach()æ˜¯ä¸ºäº†è®©å°è„‘å’Œå¤§è„‘å†³ç­–åˆ†ç¦»ä¸è¦äº’ç›¸å½±å“ï¼Œç›®çš„æ˜¯çŸ¥è¯†çš„åˆ†ç¦»ã€‚
        refined_intent = intent.detach() + 0.1 * correction

        # B. é¢„æµ‹å¹¶è®¡ç®—è¯¯å·®
        pred_final = self.cerebellum.predict_next_state(refined_intent, current_sensory)
        
        # C. åŠ¨æ€åŠ æƒ Loss
        # è¿™é‡Œç”¨ difficulty_weight ä¹˜è¿›å»ã€‚
        # å«ä¹‰ï¼šå¯¹äºé‚£äº› Predictor è§‰å¾—å¾ˆéš¾çš„æ ·æœ¬ï¼ŒCorrector ä¿®æ­£åªè¦æœ‰ä¸€ç‚¹ç‚¹æ”¹å–„ï¼Œæˆ‘ä»¬å°±ç»™äºˆå·¨å¤§çš„å¥–åŠ±ï¼ˆæ¢¯åº¦çš„åä¹‰ï¼‰ã€‚
        # åä¹‹ï¼Œå¦‚æœæœ¬æ¥å°±å¾ˆå‡†ï¼ŒCorrector ä¹±åŠ¨å¯¼è‡´ Loss å˜å¤§ï¼Œæƒ©ç½šè™½å°ä½†ç”± weight è°ƒèŠ‚ã€‚
        # å®é™…ä¸Šæˆ‘ä»¬è¦æœ€å°åŒ– lossï¼Œæ‰€ä»¥ weight è¶Šå¤§ï¼Œæƒ©ç½šè¶Šé‡ï¼Œè¿«ä½¿ Corrector æ›´å¥½åœ°é™ä½è¿™äº›éš¾æ ·æœ¬çš„è¯¯å·®ã€‚
        mse_loss = F.mse_loss(pred_final, next_sensory, reduction='none')
        loss_corr = (mse_loss * difficulty_weight * mask).mean()

        opt_corr = self.optimizers['cerebellum_corr']
        opt_corr.zero_grad()
        loss_corr.backward()
        opt_corr.step()

        for p in self.cerebellum.state_predictor.parameters():
            p.requires_grad = True

        self.losses['cerebellum_pred_raw'] = loss_pred_raw.item()
        self.losses['cerebellum_pred_refined'] = loss_pred_refined.item()
        self.losses['cerebellum_corr'] = loss_corr.item()

    def _update_brainstem_spinal(self, obs, raw_intent, sensory_state):
        """
        è„‘å¹²/è„Šé«“æ›´æ–°ï¼šè¿™æ˜¯ã€ç”Ÿç†ã€‘å±‚é¢çš„å­¦ä¹ ã€‚
        Echo æ­£åœ¨å­¦ä¹ "å¦‚ä½•æŠŠæŠ½è±¡çš„æ„å›¾ï¼Œç¿»è¯‘æˆå…·ä½“çš„è‚Œè‚‰æ”¶ç¼©"ã€‚
        """
        optimizer = self.optimizers['brainstem_spinal']
        optimizer.zero_grad()

        # 1. è¿™é‡Œçš„ intent å¿…é¡» detachï¼
        # å› ä¸ºåœ¨è¿™é‡Œï¼Œæˆ‘ä»¬ä¸è¯„ä»·æ„å›¾å¥½åï¼Œåªè¯„ä»·"æ‰§è¡Œå¾—å¥½ä¸å¥½"ã€‚
        target_intent = raw_intent.detach()
        
        # è„‘å¹²å±•å¼€
        brainstem_force, brainstem_gain = self.brainstem(target_intent)
        
        # è„Šé«“æ‰§è¡Œ
        final_action = self.spinal_cord(obs, brainstem_force, brainstem_gain, target_intent)

        # ==========================
        # æ ¸å¿ƒï¼šå¿ è¯šåº¦ & å¥åº·åº¦ Loss
        # ==========================
        # 1. å¬è¯ï¼šè„‘å¹²å‘å‡ºçš„åŠ›ï¼Œè„Šé«“è¦å¤§æ¦‚ç‡æ‰§è¡Œï¼ˆé€šè¿‡ sigmoid å½’ä¸€åŒ–æ¯”è¾ƒï¼‰
        target_action_proxy = torch.sigmoid(brainstem_force.detach()) 
        loss_follow = F.mse_loss(final_action, target_action_proxy)

        # 2. æ´»æ€§ï¼šä¸èƒ½ä¸ºäº†çœåŠ›å°±ä¸åŠ¨äº†ï¼ˆé˜²æ­¢èººå¹³ï¼‰
        synergy_std = brainstem_force.std(dim=0).mean()
        loss_active = torch.clamp(0.1 - synergy_std, min=0) 

        # 3. èŠ‚èƒ½ï¼šåŠ¨ä½œä¹Ÿè¦å°½é‡å°ï¼ˆç‰©ç†çº¦æŸï¼‰
        loss_energy = final_action.pow(2).mean()

        # 5. èº«ä½“åæœä¸€è‡´æ€§ï¼ˆå…³é”®ï¼ï¼‰ ===
        # Brainstem å¿…é¡»å­¦ä¼šï¼šæˆ‘è¾“å‡ºçš„ actionï¼Œå¤§æ¦‚ä¼šå¯¼è‡´æ€æ ·çš„æ„Ÿè§‰å˜åŒ–
        pred_sensory = self.brainstem.action_to_sensory(final_action)
        target_sensory = sensory_state.detach()
        loss_embodiment = F.mse_loss(pred_sensory, target_sensory)

        # æ€»æŸå¤±
        total_reg_loss = (
            1.0   * loss_follow +
            0.5   * loss_active +
            0e-3  * loss_energy +
            1.0  * loss_embodiment
        )

        total_reg_loss.backward()
        nn.utils.clip_grad_norm_(list(self.brainstem.parameters()) + list(self.spinal_cord.parameters()), 1.0)
        optimizer.step()

        self.losses['brainstem_spinal_follow'] = loss_follow.item()
        self.losses['brainstem_spinal_active'] = loss_active.item()
        self.losses['brainstem_spinal_energy'] = loss_energy.item()
        self.losses['brainstem_spinal_embodiment'] = loss_embodiment.item()